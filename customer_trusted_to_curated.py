from pyspark.sql import SparkSession
from pyspark.sql.functions import col, from_unixtime

# âœ… Initialize Spark Session
spark = SparkSession.builder.appName("CustomerCuratedFix").getOrCreate()

# âœ… Load Data from S3
customer_trusted_df = spark.read.parquet("s3://stedi-trusted-data/customer_trusted/")
accelerometer_trusted_df = spark.read.parquet("s3://stedi-trusted-data/accelerometer_trusted/")

# âœ… Check Schema Before Processing
print("ðŸ“Œ Customer Trusted Schema BEFORE Processing:")
customer_trusted_df.printSchema()

print("ðŸ“Œ Accelerometer Trusted Schema BEFORE Processing:")
accelerometer_trusted_df.printSchema()

# âœ… Convert `shareWithResearchAsOfDate` to TIMESTAMP if Needed
if dict(customer_trusted_df.dtypes)["shareWithResearchAsOfDate"] == "bigint":
    customer_trusted_df = customer_trusted_df.withColumn(
        "shareWithResearchAsOfDate", from_unixtime(col("shareWithResearchAsOfDate") / 1000).cast("timestamp")
    )

# âœ… Convert `timeStamp` to TIMESTAMP if Needed
if dict(accelerometer_trusted_df.dtypes)["timeStamp"] != "timestamp":
    accelerometer_trusted_df = accelerometer_trusted_df.withColumn(
        "timeStamp", col("timeStamp").cast("timestamp")
    )

# âœ… Convert INT64 fields to STRING format for Athena Compatibility
for field in ["lastUpdateDate", "registrationDate", "shareWithFriendsAsOfDate", "shareWithPublicAsOfDate"]:
    if field in dict(customer_trusted_df.dtypes) and dict(customer_trusted_df.dtypes)[field] == "bigint":
        customer_trusted_df = customer_trusted_df.withColumn(field, from_unixtime(col(field) / 1000).cast("string"))

# âœ… Check Schema After Processing
print("ðŸ“Œ Customer Trusted Schema AFTER Processing:")
customer_trusted_df.printSchema()

print("ðŸ“Œ Accelerometer Trusted Schema AFTER Processing:")
accelerometer_trusted_df.printSchema()

# âœ… Join and Filter Data
customer_curated_df = customer_trusted_df.alias("c").join(
    accelerometer_trusted_df.alias("a"),
    col("c.email") == col("a.user"),
    "inner"
).filter(
    (col("c.shareWithResearchAsOfDate").isNotNull()) &  
    (col("a.timeStamp").isNotNull()) &  
    (col("a.timeStamp") >= col("c.shareWithResearchAsOfDate"))  # âœ… Apply Consent Date Filter
).select("c.*").dropDuplicates(["email"])  # âœ… Ensure Unique Customers

# ðŸš€ Debugging: Print Final Row Count
print(f"âœ… Customers in Trusted: {customer_trusted_df.count()}")
print(f"âœ… Accelerometer Trusted Rows: {accelerometer_trusted_df.count()}")
print(f"âœ… Customers in Curated Zone: {customer_curated_df.count()}")

# âœ… Save to S3 in CORRECT FORMAT
customer_curated_df.write \
    .mode("overwrite") \
    .option("compression", "snappy") \
    .parquet("s3://stedi-curated-data/customer_curated/")

print("ðŸš€ Customer Curated Data Successfully Written!")
