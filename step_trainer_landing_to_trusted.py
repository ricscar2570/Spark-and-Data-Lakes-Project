from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# âœ… Initialize Spark Session
spark = SparkSession.builder.appName("StepTrainerTrusted").getOrCreate()

# âœ… Load Step Trainer Landing Data
step_trainer_landing_df = spark.read.option("inferSchema", "true").json("s3://stedi-raw-data/step_trainer/landing/")

# âœ… Load Customer Curated Data (Selecting Only `serialNumber`)
customer_curated_df = spark.read.parquet("s3://stedi-curated-data/customer_curated/").select("serialNumber")

# âœ… Ensure Correct Data Types
step_trainer_landing_df = step_trainer_landing_df.withColumn("sensorReadingTime", col("sensorReadingTime").cast("timestamp"))

# ðŸš€ Debugging: Print Initial Row Counts and Schema
print(f"âœ… Total Step Trainer Readings in Landing: {step_trainer_landing_df.count()}")
print(f"âœ… Customers in Curated Zone: {customer_curated_df.count()}")

print("ðŸ“Œ Step Trainer Landing Schema:")
step_trainer_landing_df.printSchema()

print("ðŸ“Œ Customer Curated Schema:")
customer_curated_df.printSchema()

# âœ… Perform the Join (Fix Duplicate Column Issue)
step_trainer_trusted_df = step_trainer_landing_df.alias("s").join(
    customer_curated_df.alias("c"),
    col("s.serialNumber") == col("c.serialNumber"),
    "inner"
).select("s.*")  # âœ… Keep Only Step Trainer Columns

# ðŸš€ Debugging: Print Final Row Count After Join
print(f"âœ… Step Trainer Readings AFTER Join with Customers: {step_trainer_trusted_df.count()}")

# âœ… Save to Trusted Zone
step_trainer_trusted_df.write.mode("overwrite").parquet("s3://stedi-trusted-data/step_trainer_trusted/")

print("ðŸš€ Step Trainer Trusted Data Successfully Written!")
