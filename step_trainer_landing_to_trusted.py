from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# âœ… Initialize Spark Session
spark = SparkSession.builder \
    .appName("StepTrainerTrusted") \
    .config("spark.sql.catalogImplementation", "hive") \
    .enableHiveSupport() \
    .getOrCreate()

# âœ… Load Step Trainer Landing Data
step_trainer_landing_df = spark.read \
    .option("inferSchema", "true") \
    .json("s3://stedi-raw-data/step_trainer/landing/")

# âœ… Load Customer Curated Data (Selecting Only `serialNumber`)
customer_curated_df = spark.read \
    .parquet("s3://stedi-curated-data/customer_curated/") \
    .select("serialNumber")

# âœ… Ensure Correct Data Types
step_trainer_landing_df = step_trainer_landing_df.withColumn("sensorReadingTime", col("sensorReadingTime").cast("timestamp"))

# ðŸš€ Debugging: Print Initial Row Counts and Schema
print(f"âœ… Total Step Trainer Readings in Landing: {step_trainer_landing_df.count()}")
print(f"âœ… Customers in Curated Zone: {customer_curated_df.count()}")

print("ðŸ“Œ Step Trainer Landing Schema:")
step_trainer_landing_df.printSchema()

print("ðŸ“Œ Customer Curated Schema:")
customer_curated_df.printSchema()

# âœ… Perform the Join (Fix Duplicate Column Issue)
step_trainer_trusted_df = step_trainer_landing_df.alias("s").join(
    customer_curated_df.alias("c"),
    col("s.serialNumber") == col("c.serialNumber"),
    "inner"
).select("s.*")  # âœ… Keep Only Step Trainer Columns

# ðŸš€ Debugging: Print Final Row Count After Join
print(f"âœ… Step Trainer Readings AFTER Join with Customers: {step_trainer_trusted_df.count()}")

# âœ… Enable schema evolution in Glue Data Catalog
step_trainer_trusted_df.write \
    .mode("overwrite") \
    .format("parquet") \
    .option("path", "s3://stedi-trusted-data/step_trainer_trusted/") \
    .option("mergeSchema", "true") \
    .saveAsTable("stedi.step_trainer_trusted")

print("ðŸš€ Step Trainer Trusted Data Successfully Written!")

# âœ… Stop Spark Session
spark.stop()
